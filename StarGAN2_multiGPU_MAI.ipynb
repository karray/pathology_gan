{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from stargan2.solver_multi_GPU import Solver\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torchvision.models.resnet as resnet\n",
    "\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from itertools import groupby\n",
    "import random\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "class ReferenceDataset(datasets.DatasetFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            loader = datasets.folder.default_loader,\n",
    "            is_valid_file = None,\n",
    "    ):\n",
    "        super(ReferenceDataset, self).__init__(root, loader, \n",
    "                                          datasets.folder.IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                          transform=transform,\n",
    "                                          target_transform=target_transform,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "        \n",
    "        # group samples by label\n",
    "        groupped = {k: list(v) for k, v in  groupby(self.samples, lambda x: x[1])}\n",
    "        \n",
    "        # crate reference images\n",
    "        references = []\n",
    "        targets = []\n",
    "        for domain, values in groupped.items():\n",
    "            # unzip samples and targets\n",
    "            samples, _ = zip(*values)\n",
    "            # shuffle second reference images\n",
    "            samples2 = random.sample(samples, len(samples))\n",
    "            # repeat labels\n",
    "            labels = [domain]*len(samples)\n",
    "            targets+= labels\n",
    "            references+= list(zip(samples, samples2, labels))\n",
    "        # override samples\n",
    "        self.samples = references\n",
    "        # override targets to make sure that the samples have corresponding labels\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (ref sample 1, ref sample 2, ref target)\n",
    "        \"\"\"\n",
    "        ref_path1, ref_path2, ref_target = self.samples[index]\n",
    "\n",
    "        ref1 = self.loader(ref_path1)\n",
    "        ref2 = self.loader(ref_path2)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            ref1 = self.transform(ref1)\n",
    "            ref2 = self.transform(ref2)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            ref_target = self.target_transform(ref_target)\n",
    "\n",
    "        return ref1, ref2, ref_target\n",
    "\n",
    "def make_balanced_sampler(labels):\n",
    "    class_counts = np.bincount(labels)\n",
    "    class_weights = 1. / class_counts\n",
    "    weights = class_weights[labels]\n",
    "    WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_size = 128\n",
    "batch_size = 8\n",
    "num_workers = 4\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([img_size, img_size]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "ds = ImageFolder('data/mai', transform)\n",
    "ds_ref = ReferenceDataset('data/mai', transform)\n",
    "\n",
    "sampler = make_balanced_sampler(ds.targets)\n",
    "loader = DataLoader(dataset=ds,\n",
    "                    batch_size=batch_size,\n",
    "                    sampler=sampler,\n",
    "                    shuffle=True,\n",
    "                    num_workers=num_workers,\n",
    "                    pin_memory=True,\n",
    "                    drop_last=True)\n",
    "\n",
    "sampler_ref = make_balanced_sampler(ds_ref.targets)\n",
    "loader_ref = DataLoader(dataset=ds_ref,\n",
    "                        batch_size=batch_size,\n",
    "                        sampler=sampler_ref,\n",
    "                        shuffle=True,\n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_domains: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'wsi1_tiles': 0, 'wsi2_tiles': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains, domains_mapping = ds._find_classes(ds.root)\n",
    "n_domains = len(domains)\n",
    "print('n_domains:', n_domains)\n",
    "domains_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = Solver('StarGAN2_MAI_128', 'ds1', img_size, n_domains=2, lambda_ds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marray\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.22 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">still-donkey-4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/array/StarGAN2_MAI_128\" target=\"_blank\">https://wandb.ai/array/StarGAN2_MAI_128</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/array/StarGAN2_MAI_128/runs/18fogekf\" target=\"_blank\">https://wandb.ai/array/StarGAN2_MAI_128/runs/18fogekf</a><br/>\n",
       "                Run data is saved locally in <code>/data/aray/pathology_gan/wandb/run-20210319_182823-18fogekf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    }
   ],
   "source": [
    "solver.train(100000, loader, loader_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/StarGAN2_1_afhq_256'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.working_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
