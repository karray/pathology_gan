{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import IPython\n",
    "\n",
    "# from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import data, color\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Dense,Reshape, Flatten, Conv2DTranspose, Dropout,BatchNormalization,Activation,PReLU,LeakyReLU,MaxoutDense,Add\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras import initializers\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true,y_pred):\n",
    "    return K.mean(y_true*y_pred)\n",
    "\n",
    "def init_folders(name):\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkdir('results')\n",
    "    if not os.path.exists('results/'+name):\n",
    "        os.mkdir('results/'+name)\n",
    "        \n",
    "def save_loss(name, epoch, Dloss, Gloss):\n",
    "    path = 'results/'+name+'/loss'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(Dloss,label='Dsicriminiative loss')\n",
    "    plt.plot(Gloss,label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(path+'/loss_%d.png' % epoch)\n",
    "    \n",
    "def save_samples(folder, w, h, c, epoch, G,example=16, dim=(10,10),figsize=(10,10), randomDim=100):\n",
    "    noise = np.random.normal(0,1,size=(example,randomDim))\n",
    "    generatedImage = G.predict(noise)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i in range(example):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        plt.imshow((generatedImage[i]* 127.5+127.5).astype(np.int32),interpolation='nearest',cmap='gray')\n",
    "        '''drop the x and y axis'''\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    path = 'results/'+folder+'/samples'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(path+'/epoch_%d.png' % epoch)\n",
    "    \n",
    "def save_models(name, epoch, d=None, g=None):\n",
    "    path = 'results/'+name+'/models'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    g.save(path+'/G_%d.h5' % epoch)\n",
    "    d.save(path+'/D_%d.h5' % epoch)\n",
    "    \n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "\n",
    "\n",
    "# class CustomDataProvider:\n",
    "#     def __init__(self, batch_size):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.file = h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')\n",
    "#         self.dataset = self.file['x']\n",
    "#         self.input_shape = self.dataset[0].shape\n",
    "#         self.image_number = self.dataset.shape[0]\n",
    "        \n",
    "#     def sample(self):\n",
    "#         random_index = np.random.randint(0, self.image_number - self.batch_size)\n",
    "#         return (self.dataset[random_index : random_index +  self.batch_size] - 127.5) / 127.5\n",
    "        \n",
    "#     def close(self):\n",
    "#         if self.file:\n",
    "#             self.file.close()\n",
    "#         self.file = None\n",
    "        \n",
    "#     def __del__(self):\n",
    "#         self.close()\n",
    "\n",
    "class PcamDataProvider:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.file = h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')\n",
    "        self.dataset = self.file['x']\n",
    "        self.input_shape = self.dataset[0].shape\n",
    "        self.image_number = self.dataset.shape[0]\n",
    "        \n",
    "    def sample(self):\n",
    "        random_index = np.random.randint(0, self.image_number - self.batch_size)\n",
    "        return (self.dataset[random_index : random_index +  self.batch_size] - 127.5) / 127.5\n",
    "        \n",
    "    def close(self):\n",
    "        if self.file:\n",
    "            self.file.close()\n",
    "        self.file = None\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "        \n",
    "        \n",
    "def create_critic_final(width, height, channels, kernel_size=3):\n",
    "    \"\"\" Declare discriminator \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2), \n",
    "                     kernel_size=kernel_size, strides=2, \n",
    "                     input_shape=(width, height, channels), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(1,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "\n",
    "    print('Critic')\n",
    "    model.summary()\n",
    "#     model.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_actor_final(width, height, channels, latent_dim=100):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32*int(width/4)*int(height/4), input_dim=latent_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((int(width/4),int(height/4), 32)))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(48, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    " \n",
    "    model.add(Conv2D(8, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(4, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(channels, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    print('Actor')\n",
    "    model.summary()    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic1(width, height, channels, kernel_size=3):\n",
    "    \"\"\" Declare discriminator \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(256, kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2), \n",
    "                     kernel_size=kernel_size, strides=2, \n",
    "                     input_shape=(width, height, channels), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(1024, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(512,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    model.add(Dense(1,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "\n",
    "    print('Critic')\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic_kernel(width, height, channels):\n",
    "    \"\"\" Declare discriminator \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2), \n",
    "                     kernel_size=4, strides=2, \n",
    "                     input_shape=(width, height, channels), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(1,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "\n",
    "    print('Critic')\n",
    "    model.summary()\n",
    "#     model.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_actor_kernel(width, height, channels, latent_dim=100):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32*int(width/4)*int(height/4), input_dim=latent_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((int(width/4),int(height/4), 32)))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(48, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(32, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    " \n",
    "    model.add(Conv2D(8, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(channels, kernel_size=4, strides=1, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    print('Actor')\n",
    "    model.summary()    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor_skip_connections(width, height, channels, latent_dim=100):\n",
    "    \n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "    X = Dense(32*int(width/4)*int(height/4), input_dim=latent_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(inputs)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Reshape((int(width/4),int(height/4), 32))(X)\n",
    "\n",
    "    X_shortcut = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = Conv2D(64, kernel_size=3, strides=1, padding=\"same\")(X_shortcut)\n",
    "    X_shortcut = Conv2D(64, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X_shortcut = Activation('relu')(X)\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X_shortcut)\n",
    "    X = Conv2D(48, kernel_size=4, strides=2, padding=\"same\")(X)\n",
    "    X_shortcut = Conv2D(48, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])    \n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X_shortcut = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = Conv2D(32, kernel_size=3, strides=1, padding=\"same\")(X_shortcut)\n",
    "    X_shortcut = Conv2D(32, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X_shortcut = Activation('relu')(X)\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X_shortcut)\n",
    "    X = Conv2D(16, kernel_size=4, strides=2, padding=\"same\")(X)\n",
    "    X_shortcut = Conv2D(16, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X_shortcut = Activation('relu')(X)\n",
    " \n",
    "    X = Conv2D(8, kernel_size=3, strides=1, padding=\"same\")(X_shortcut)\n",
    "    X_shortcut = Conv2D(8, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X_shortcut = Activation('relu')(X)\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X_shortcut)\n",
    "    X = Conv2D(4, kernel_size=4, strides=2, padding=\"same\")(X)\n",
    "    X_shortcut = Conv2D(4, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X_shortcut = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(channels, kernel_size=3, strides=1, padding=\"same\")(X_shortcut)\n",
    "    X_shortcut = Conv2D(channels, kernel_size=1, strides=1, padding='same')(X_shortcut)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    outputs = Activation(\"tanh\")(X)\n",
    "    \n",
    "    print('Actor')\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Actor')\n",
    "    model.summary()    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X_shortcut)\n",
    "#     X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def id_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c',\n",
    "               kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "#     X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic_res(width, height, channels):\n",
    "    \n",
    "    inputs = Input(shape=(width,height,channels))\n",
    "    \n",
    "    X = Conv2D(32, kernel_size=6, strides=2, padding=\"same\",\n",
    "              kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(inputs)\n",
    "    X = LeakyReLU(alpha=0.1)(X)\n",
    "    \n",
    "    X = conv_block(X, f=3, filters = [16, 16, 64], stage = 1, block='a', s=2)\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=1, block='b')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=1, block='c')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=1, block='d')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=1, block='e')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=1, block='f')    \n",
    "\n",
    "    X = conv_block(X, f=3, filters = [32, 32, 128], stage = 2, block='a', s=2)\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='d')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='e')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='f')      \n",
    "\n",
    "    X = conv_block(X, f=3, filters = [64, 64, 256], stage = 3, block='a', s=2)\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=3, block='b')\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=3, block='c')\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=3, block='d')\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=3, block='e')\n",
    "    X = id_block(X, 3, [64, 64, 256], stage=3, block='f')    \n",
    "\n",
    "    X = conv_block(X, f=3, filters = [128, 128, 512], stage = 4, block='a', s=1)\n",
    "    X = id_block(X, 3, [128, 128, 512], stage=4, block='b')\n",
    "    X = id_block(X, 3, [128, 128, 512], stage=4, block='c')\n",
    "    X = id_block(X, 3, [128, 128, 512], stage=4, block='d')    \n",
    "    X = id_block(X, 3, [128, 128, 512], stage=4, block='e')    \n",
    "    X = id_block(X, 3, [128, 128, 512], stage=4, block='f')    \n",
    "    \n",
    "    X = conv_block(X, f=3, filters=[128, 128, 1024], stage=5, block='a', s=1)\n",
    "    X = id_block(X, 3, [128, 128, 1024], stage=5, block='b')\n",
    "    X = id_block(X, 3, [128, 128, 1024], stage=5, block='c')\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "    X = LeakyReLU(alpha=0.1)(X)\n",
    "    outputs = Dense(1, kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "\n",
    "\n",
    "    print('Critic')\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Critic')\n",
    "    model.summary()    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_actor_res(width, height, channels, latent_dim=100):\n",
    "    \n",
    "    inputs = Input(shape=(latent_dim,))\n",
    "\n",
    "    first_filters = 128\n",
    "    k = 4\n",
    "    \n",
    "    X = Dense(first_filters*int(width/k)*int(height/k), input_dim=latent_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(inputs)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Reshape((int(width/k),int(height/k), first_filters))(X)\n",
    "\n",
    "    # Zero-Padding\n",
    "#     X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    X = Conv2D(first_filters, kernel_size=3, strides=1, padding=\"same\",\n",
    "              kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "\n",
    "    X = conv_block(X, f=3, filters=[32, 32, 128], stage=1, block='a', s=1)\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=1, block='b')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=1, block='c')\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = conv_block(X, f = 3, filters = [32, 32, 128], stage = 2, block='a', s = 1)\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='c')\n",
    "    X = id_block(X, 3, [32, 32, 128], stage=2, block='d')\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = conv_block(X, f = 3, filters = [16, 16, 64], stage = 3, block='a', s = 1)\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=3, block='b')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=3, block='c')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=3, block='d')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=3, block='e')\n",
    "    X = id_block(X, 3, [16, 16, 64], stage=3, block='f')\n",
    "\n",
    "    X = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = conv_block(X, f = 3, filters = [8, 8, 32], stage = 4, block='a', s = 2)\n",
    "    X = id_block(X, 3, [8, 8, 32], stage=4, block='b')\n",
    "    X = id_block(X, 3, [8, 8, 32], stage=4, block='c')\n",
    "    X = id_block(X, 3, [8, 8, 32], stage=4, block='d')\n",
    "    X = id_block(X, 3, [8, 8, 32], stage=4, block='e')\n",
    "    X = id_block(X, 3, [8, 8, 32], stage=4, block='f')    \n",
    "\n",
    "#     X = UpSampling2D(interpolation='nearest')(X)\n",
    "    X = conv_block(X, f = 3, filters = [4, 4, 16], stage = 5, block='a', s = 1)\n",
    "    X = id_block(X, 3, [4, 4, 16], stage=5, block='b')\n",
    "    X = id_block(X, 3, [4, 4, 16], stage=5, block='c')\n",
    "    X = id_block(X, 3, [4, 4, 16], stage=5, block='d')\n",
    "    X = id_block(X, 3, [4, 4, 16], stage=5, block='e')\n",
    "    X = id_block(X, 3, [4, 4, 16], stage=5, block='f')    \n",
    "    \n",
    "    X = Conv2D(channels, kernel_size=3, strides=1, padding=\"same\",\n",
    "              kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2))(X)\n",
    "    outputs = Activation(\"tanh\")(X)\n",
    "    \n",
    "    print('Actor')\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Actor')\n",
    "    model.summary()    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, critic, actor, sampler, epochs=3000, randomDim=100, do_save_loss=True, do_save_models=True, do_save_samples=True, batchCount=128, epoch_offset=0):\n",
    "    \"\"\"\n",
    "    :name: name of the directory, which will store all data\n",
    "    :critic: model for critic\n",
    "    :actor: model for critic\n",
    "    \"\"\"\n",
    "    \n",
    "    init_folders(name)\n",
    "\n",
    "    batchsize = sampler.batch_size\n",
    "\n",
    "    width, height, channels = sampler.input_shape\n",
    "\n",
    "    critic.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "    generator = actor\n",
    "    discriminator = critic\n",
    "\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input((randomDim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "\n",
    "    gan = Model(gan_input,gan_output)\n",
    "    gan.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    Dloss = []\n",
    "    Gloss = []\n",
    "\n",
    "    print('Actor', get_model_memory_usage(batchsize, generator), 'GB')\n",
    "    print('Critic', get_model_memory_usage(batchsize*2, discriminator), 'GB')\n",
    "    \n",
    "    print('Epochs',epochs)\n",
    "    print('Bathc size',batchsize)\n",
    "    print('Batches per epoch',batchCount)\n",
    "\n",
    "    for e in range(epoch_offset+1,epochs+1):\n",
    "#         print('-'*15 , 'Epoch %d' % e , '-'*15)\n",
    "#         start_time = time.time()\n",
    "        for _ in tqdm(range(batchCount), desc=\"epoch \"+str(e)):\n",
    "#             print('.', end='')\n",
    "            imageBatch = sampler.sample()\n",
    "            \n",
    "            #Get a random set of input noise and images\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            generatedImages = generator.predict(noise)\n",
    "            \n",
    "            X = np.concatenate([imageBatch,generatedImages])\n",
    "            \n",
    "            yDis = np.ones(2*batchsize)\n",
    "            \n",
    "            yDis[:batchsize] = -1\n",
    "            \n",
    "            #Train critic\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            ### Clip weights ###\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in discriminator.get_weights()]\n",
    "            discriminator.set_weights(weights)\n",
    "            \n",
    "            dloss = discriminator.train_on_batch(X,yDis)\n",
    "            \n",
    "            #Train actor\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            yGen = np.ones(batchsize) * -1\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise,yGen)\n",
    "            \n",
    "#         print('episode time', time.time()-start_time)\n",
    "\n",
    "        if do_save_loss:\n",
    "            Dloss.append(dloss)\n",
    "            Gloss.append(gloss)\n",
    "\n",
    "        if e ==1 or e % 10 == 0:            \n",
    "            if do_save_loss:\n",
    "                Dloss.append(dloss)\n",
    "                Gloss.append(gloss)\n",
    "                save_loss(name, e, Dloss, Gloss)\n",
    "            if do_save_samples:\n",
    "                save_samples(name, width, height, channels, e, generator, 16, dim=(4,4))\n",
    "            if do_save_models:\n",
    "                save_models(name, e, d=discriminator, g=generator)\n",
    "\n",
    "                \n",
    "def train_multigpu(name, critic, actor, sampler_class, gpus,\n",
    "                   batch_size = 64,\n",
    "                   epochs=3000,\n",
    "                   randomDim=100,\n",
    "                   do_save_loss=True, \n",
    "                   do_save_models=True, \n",
    "                   do_save_samples=True, \n",
    "                   batchCount=128, \n",
    "                   epoch_offset=0):\n",
    "    \"\"\"\n",
    "    :name: name of the directory, which will store all data\n",
    "    :critic: model for critic\n",
    "    :actor: model for critic\n",
    "    \"\"\"\n",
    "    \n",
    "    init_folders(name)\n",
    "    \n",
    "    sampler = sampler_class(batch_size*gpus)\n",
    "\n",
    "    batchsize = sampler.batch_size\n",
    "\n",
    "    width, height, channels = sampler.input_shape\n",
    "\n",
    "    discriminator = multi_gpu_model(critic, gpus=gpus)\n",
    "    discriminator.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    generator = actor\n",
    "\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input((randomDim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "    \n",
    "    gan_model = Model(gan_input,gan_output)\n",
    "    \n",
    "    gan = multi_gpu_model(gan_model, gpus=gpus)\n",
    "    gan.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    Dloss = []\n",
    "    Gloss = []\n",
    "\n",
    "    print('Actor', get_model_memory_usage(batchsize/gpus, generator), 'GB')\n",
    "    print('Critic', get_model_memory_usage(batchsize*2/gpus, discriminator), 'GB')\n",
    "    \n",
    "    print('Epochs',epochs)\n",
    "    print('gpus',gpus)\n",
    "    print('Batch size per gpu',batchsize/gpus)\n",
    "    print('Batches per epoch',batchCount)\n",
    "\n",
    "    for e in range(epoch_offset+1,epochs+1):\n",
    "#         print('-'*15 , 'Epoch %d' % e , '-'*15)\n",
    "#         start_time = time.time()\n",
    "        gloss = []\n",
    "        dloss = []\n",
    "        for _ in tqdm(range(batchCount), desc=\"epoch \"+str(e)):\n",
    "#             print('.', end='')\n",
    "            imageBatch = sampler.sample()\n",
    "            \n",
    "            #Get a random set of input noise and images\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            generatedImages = generator.predict(noise)\n",
    "            \n",
    "            X = np.concatenate([imageBatch,generatedImages])\n",
    "            \n",
    "            yDis = np.ones(2*batchsize)\n",
    "            \n",
    "            yDis[:batchsize] = -1\n",
    "            \n",
    "            #Train critic\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            ### Clip weights ###\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in discriminator.get_weights()]\n",
    "            discriminator.set_weights(weights)\n",
    "            \n",
    "            dloss.append(discriminator.train_on_batch(X,yDis))\n",
    "            \n",
    "            #Train actor\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            yGen = np.ones(batchsize) * -1\n",
    "            discriminator.trainable = False\n",
    "            gloss.append(gan.train_on_batch(noise,yGen))\n",
    "            \n",
    "#         print('episode time', time.time()-start_time)\n",
    "\n",
    "        if do_save_loss:\n",
    "            Dloss.append(np.mean(dloss))\n",
    "            Gloss.append(np.mean(gloss))\n",
    "                \n",
    "        if e ==1 or e % 10 == 0:            \n",
    "            if do_save_loss:\n",
    "                save_loss(name, e, Dloss, Gloss)\n",
    "            if do_save_samples:\n",
    "                save_samples(name, width, height, channels, e, generator, 16, dim=(4,4),randomDim=randomDim)\n",
    "            if do_save_models:\n",
    "                save_models(name, e, d=critic, g=actor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic = load_model('results/WGAN_multi_gpu_critic1/models/D_170.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "# actor = load_model('results/WGAN_multi_gpu_critic1/models/G_170.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "critic = create_critic_res(96, 96, 3)\n",
    "actor = create_actor_final(96, 96, 3, latent_dim=100)\n",
    "\n",
    "# IPython.display.SVG(model_to_dot(actor).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multigpu('WGAN_critic_res', critic, actor, PcamDataProvider, gpus=4, batch_size=64, epochs=10000, randomDim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, data_path, critic, actor, epochs=3000, batchsize=64, do_save_loss=True, do_save_models=True, do_save_samples=True, batchCount=128, epoch_offset=0):\n",
    "    \"\"\"\n",
    "    :name: name of the directory, which will store all data\n",
    "    :data_path: path to real samples\n",
    "    :critic: model for critic\n",
    "    :actor: model for critic\n",
    "    \"\"\"\n",
    "    \n",
    "    init_folders(name)\n",
    "\n",
    "    filelist = glob.glob(os.path.join(data_path,'*.jpg'))\n",
    "    \n",
    "    image_number = len(filelist)\n",
    "\n",
    "    width, height, channels = 256, 256, 3\n",
    "\n",
    "    randomDim = 100\n",
    "\n",
    "    generator = actor\n",
    "    discriminator = critic\n",
    "\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input((randomDim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "\n",
    "    gan = Model(gan_input,gan_output)\n",
    "    gan.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    Dloss = []\n",
    "    Gloss = []\n",
    "\n",
    "    print('Actor', get_model_memory_usage(batchsize, generator), 'GB')\n",
    "    print('Critic', get_model_memory_usage(batchsize*2, discriminator), 'GB')\n",
    "    \n",
    "    print('Epochs',epochs)\n",
    "    print('Bathc size',batchsize)\n",
    "    print('Batches per epoch',batchCount)\n",
    "\n",
    "    for e in range(epoch_offset+1,epochs+1):\n",
    "        print('-'*15 , 'Epoch %d' % e , '-'*15)\n",
    "        for _ in range(batchCount):\n",
    "            print('.', end='')\n",
    "            random_index = np.random.randint(0, image_number - batchsize)\n",
    "            imageBatch = np.array([data.imread(fname) for fname in filelist[random_index : random_index + batchsize]]).reshape(batchsize, width, height, channels)\n",
    "            imageBatch = (imageBatch.astype(np.float32) - 127.5) / 127.5\n",
    "            \n",
    "            #Get a random set of input noise and images\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            generatedImages = generator.predict(noise)\n",
    "            \n",
    "            X = np.concatenate([imageBatch,generatedImages])\n",
    "            \n",
    "            yDis = np.ones(2*batchsize)\n",
    "            \n",
    "            yDis[:batchsize] = -1\n",
    "            \n",
    "            #Train critic\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            ### Clip weights ###\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in discriminator.get_weights()]\n",
    "            discriminator.set_weights(weights)\n",
    "            \n",
    "            dloss = discriminator.train_on_batch(X,yDis)\n",
    "            \n",
    "            #Train actor\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            yGen = np.ones(batchsize) * -1\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise,yGen)\n",
    "            \n",
    "\n",
    "        if do_save_loss:\n",
    "            Dloss.append(dloss)\n",
    "            Gloss.append(gloss)\n",
    "            save_loss(name, e, Dloss, Gloss)\n",
    "        if do_save_samples:\n",
    "            save_samples(name, width, height, channels, e, generator, 16, dim=(4,4))\n",
    "        if do_save_models:\n",
    "            save_models(name, e, d=discriminator, g=generator)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
