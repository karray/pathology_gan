{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "# from tqdm import tnrange, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import data, color\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.activations import relu\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Dense,Reshape, Flatten, Conv2DTranspose, Dropout,BatchNormalization,Activation,PReLU,LeakyReLU,MaxoutDense\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras import initializers\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_folders(name):\n",
    "    if not os.path.exists('results'):\n",
    "        os.mkdir('results')\n",
    "    if not os.path.exists('results/'+name):\n",
    "        os.mkdir('results/'+name)\n",
    "        \n",
    "def save_loss(name, epoch, Dloss, Gloss):\n",
    "    path = 'results/'+name+'/loss'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(Dloss,label='Dsicriminiative loss')\n",
    "    plt.plot(Gloss,label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(path+'/loss_%d.png' % epoch)\n",
    "    \n",
    "def save_samples(folder, epoch, G,example=16, dim=(10,10),figsize=(10,10), randomDim=100):\n",
    "    noise = np.random.normal(0,1,size=(example,randomDim))\n",
    "    generatedImage = G.predict(noise)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i in range(example):\n",
    "        plt.subplot(dim[0],dim[1],i+1)\n",
    "        plt.imshow((.5*generatedImage[i] + .5), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    path = 'results/'+folder+'/samples'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    plt.savefig(path+'/epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "    \n",
    "def save_models(name, epoch, d=None, g=None):\n",
    "    path = 'results/'+name+'/models'\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    g.save(path+'/G_%d.h5' % epoch)\n",
    "    d.save(path+'/D_%d.h5' % epoch)\n",
    "    \n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if K.floatx() == 'float16':\n",
    "         number_size = 2.0\n",
    "    if K.floatx() == 'float64':\n",
    "         number_size = 8.0\n",
    "\n",
    "    total_memory = number_size*(batch_size*shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes\n",
    "\n",
    "\n",
    "# class CustomDataProvider:\n",
    "#     def __init__(self, batch_size):\n",
    "#         self.batch_size = batch_size\n",
    "#         self.file = h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')\n",
    "#         self.dataset = self.file['x']\n",
    "#         self.input_shape = self.dataset[0].shape\n",
    "#         self.image_number = self.dataset.shape[0]\n",
    "        \n",
    "#     def sample(self):\n",
    "#         random_index = np.random.randint(0, self.image_number - self.batch_size)\n",
    "#         return (self.dataset[random_index : random_index +  self.batch_size] - 127.5) / 127.5\n",
    "        \n",
    "#     def close(self):\n",
    "#         if self.file:\n",
    "#             self.file.close()\n",
    "#         self.file = None\n",
    "        \n",
    "#     def __del__(self):\n",
    "#         self.close()\n",
    "\n",
    "class PcamDataProvider:\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.file = h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')\n",
    "        self.dataset = self.file['x']\n",
    "        self.input_shape = self.dataset[0].shape\n",
    "        self.image_number = self.dataset.shape[0]\n",
    "        \n",
    "    def sample(self):\n",
    "        random_index = np.random.randint(0, self.image_number - self.batch_size)\n",
    "        return (self.dataset[random_index : random_index +  self.batch_size] - 127.5) / 127.5\n",
    "        \n",
    "    def close(self):\n",
    "        if self.file:\n",
    "            self.file.close()\n",
    "        self.file = None\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true,y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_critic_final(width, height, channels, kernel_size=3):\n",
    "    \"\"\" Declare discriminator \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2), \n",
    "                     kernel_size=kernel_size, strides=2, \n",
    "                     input_shape=(width, height, channels), padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\",\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(0.15))\n",
    "\n",
    "    model.add(Dense(1,\n",
    "             kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final actor ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actor_final(width, height, channels, latent_dim=100):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32*int(width/4)*int(height/4), input_dim=latent_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(mean=0,stddev=0.2)))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Reshape((int(width/4),int(height/4), 32)))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(48, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    " \n",
    "    model.add(Conv2D(8, kernel_size=3, strides=1, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(UpSampling2D(interpolation='nearest'))\n",
    "    model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "#     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(channels, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training method ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(name, critic, actor, data,\n",
    "          batch_size=64,\n",
    "          epochs=3000, \n",
    "          randomDim=100, \n",
    "          do_save_loss=True, \n",
    "          do_save_models=True, \n",
    "          do_save_samples=True, \n",
    "          batchCount=1, \n",
    "          epoch_offset=0):\n",
    "    \"\"\"\n",
    "    :name: name of the directory, which will store all data\n",
    "    :critic: model for critic\n",
    "    :actor: model for critic\n",
    "    \"\"\"\n",
    "    \n",
    "    init_folders(name)\n",
    "\n",
    "    batchsize = batch_size\n",
    "\n",
    "    width, height, channels = 64,64,3\n",
    "\n",
    "    critic.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "    generator = actor\n",
    "    discriminator = critic\n",
    "\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input((randomDim,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output = discriminator(x)\n",
    "\n",
    "    gan = Model(gan_input,gan_output)\n",
    "    gan.compile(loss=wasserstein_loss,optimizer=RMSprop(lr=0.00005))\n",
    "\n",
    "    Dloss = []\n",
    "    Gloss = []\n",
    "\n",
    "#     print('Actor', get_model_memory_usage(batchsize, generator), 'GB')\n",
    "#     print('Critic', get_model_memory_usage(batchsize*2, discriminator), 'GB')\n",
    "    \n",
    "#     print('Epochs',epochs)\n",
    "#     print('Bathc size',batchsize)\n",
    "#     print('Batches per epoch',batchCount)\n",
    "    yGen = -np.ones(batchsize)\n",
    "    for e in range(epochs):\n",
    "        for idx in tqdm(np.array_split(shuffle(range(data.shape[0])), batchsize), desc=\"epoch \"+str(e)):\n",
    "            imageBatch = data[idx]\n",
    "\n",
    "            noise = np.random.normal(0,1,size=[idx.shape[0], randomDim])\n",
    "            generatedImages = generator.predict(noise)\n",
    "            \n",
    "            X_rg = np.concatenate([imageBatch,generatedImages])\n",
    "\n",
    "            #Train critic\n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            ### Clip weights ###\n",
    "            weights = [np.clip(w, -0.01, 0.01) for w in discriminator.get_weights()]\n",
    "            discriminator.set_weights(weights)\n",
    "            \n",
    "            yDis = np.ones(2*idx.shape[0])\n",
    "            yDis[:idx.shape[0]] = -1\n",
    "            dloss = discriminator.train_on_batch(X_rg, yDis)\n",
    "            \n",
    "            #Train actor\n",
    "            noise = np.random.normal(0,1,size=[batchsize,randomDim])\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise,yGen)\n",
    "\n",
    "#             if e%100 == 0:\n",
    "        save_samples(name, e, generator, 16, dim=(4,4))\n",
    "        save_models(name, e, d=discriminator, g=generator)\n",
    "\n",
    "    save_samples(name, epochs, generator, 16, dim=(4,4))\n",
    "    save_models(name, epochs, d=discriminator, g=generator)\n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(np.array(Gloss), label='G')\n",
    "#     plt.plot(np.array(Dloss), label='D')\n",
    "#     plt.legend()\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327680, 64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = (h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "x_test = (h5py.File('camelyonpatch_level_2_split_test_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "x_valid = (h5py.File('camelyonpatch_level_2_split_valid_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "X = np.concatenate([x_train, x_test, x_valid])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# critic = load_model('results/WGAN_multi_gpu_critic1/models/D_170.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "# actor = load_model('results/WGAN_multi_gpu_critic1/models/G_170.h5', custom_objects={'wasserstein_loss': wasserstein_loss})\n",
    "critic = create_critic_final(64, 64, 3)\n",
    "actor = create_actor_final(64, 64, 3, latent_dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0: 100%|██████████| 64/64 [04:35<00:00,  4.31s/it]\n",
      "epoch 1: 100%|██████████| 64/64 [04:26<00:00,  4.16s/it]\n",
      "epoch 2: 100%|██████████| 64/64 [04:26<00:00,  4.16s/it]\n",
      "epoch 3: 100%|██████████| 64/64 [04:25<00:00,  4.15s/it]\n",
      "epoch 4: 100%|██████████| 64/64 [04:25<00:00,  4.15s/it]\n",
      "epoch 5:  97%|█████████▋| 62/64 [04:18<00:08,  4.11s/it]"
     ]
    }
   ],
   "source": [
    "train('WGAN', critic, actor, X, batch_size=64, epochs=10000, randomDim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
