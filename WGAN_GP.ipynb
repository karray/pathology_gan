{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' \n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "# from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Add\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, LeakyReLU\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# from tensorflow.compat.v1.keras.backend import set_session\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "# config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "# graph = tf.compat.v1.get_default_graph()\n",
    "# set_session(sess)\n",
    "\n",
    "# import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _compute_gradients(tensor, var_list):\n",
    "#     grads = tf.gradients(tensor, var_list)\n",
    "#     return [grad if grad is not None else tf.zeros_like(var)\n",
    "#           for var, grad in zip(var_list, grads)]\n",
    "\n",
    "class RandomWeightedAverage(Add):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        input1, input2 = inputs\n",
    "        alpha = K.random_uniform((K.shape(input1)[0], 1, 1, 1))\n",
    "        return (alpha * input1) + ((1 - alpha) * input2)\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self, width, height, channels):\n",
    "        self.img_rows = width\n",
    "        self.img_cols = height\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(self.latent_dim,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "#         with tf.GradientTape() as tape:\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    \n",
    "    def build_critic(self):\n",
    "        kernel_size = 4\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=kernel_size, strides=2, \n",
    "                         input_shape=(self.img_rows, self.img_cols, self.channels), padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=kernel_size, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=kernel_size, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.1))\n",
    "        model.add(Dropout(0.15))\n",
    "\n",
    "        model.add(Dense(1))    \n",
    "    \n",
    "        return model\n",
    "    \n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(32*int(self.img_rows/4)*int(self.img_cols/4), input_dim=self.latent_dim))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Reshape((int(self.img_rows/4),int(self.img_cols/4), 32)))\n",
    "\n",
    "        model.add(UpSampling2D(interpolation='nearest'))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(UpSampling2D(interpolation='nearest'))\n",
    "        model.add(Conv2D(48, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(UpSampling2D(interpolation='nearest'))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(UpSampling2D(interpolation='nearest'))\n",
    "        model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(8, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(UpSampling2D(interpolation='nearest'))\n",
    "        model.add(Conv2D(16, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    #     model.add(BatchNormalization(momentum=0.9, epsilon=0.00002))\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        print('Actor')\n",
    "        model.summary()    \n",
    "\n",
    "        return model        \n",
    "        \n",
    "    def build_generator1(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 8 * 8, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((8, 8, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(32, kernel_size=4, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "#         model.add(UpSampling2D())\n",
    "#         model.add(Conv2D(16, kernel_size=4, padding=\"same\"))\n",
    "#         model.add(BatchNormalization(momentum=0.8))\n",
    "#         model.add(Activation(\"relu\"))        \n",
    "        \n",
    "        model.add(Conv2D(self.channels, kernel_size=4, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "#         model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_critic1(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1))\n",
    "\n",
    "#         model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size, sample_interval=50):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((batch_size, 1))\n",
    "        fake =  np.ones((batch_size, 1))\n",
    "        dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        for epoch in range(epochs):\n",
    "            for idx in tqdm(np.array_split(shuffle(range(X_train.shape[0])), X_train.shape[0]/batch_size), desc=\"epoch \"+str(epoch)):\n",
    "#             for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "#                 idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (idx.shape[0], self.latent_dim))\n",
    "                # Train the critic\n",
    "                y = np.ones((batch_size, 1))\n",
    "                y_dummy = np.zeros((idx.shape[0], 1))\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise], [-y, y, y_dummy])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "                g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "#             print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "#             if epoch % sample_interval == 0:\n",
    "            self.sample_images('wgan_gp', epoch)\n",
    "            self.save_models('wgan_gp', epoch)\n",
    "        self.sample_images('wgan_gp', epochs)\n",
    "        self.save_models('wgan_gp', epochs)\n",
    "\n",
    "    def sample_images(self, folder, epoch):\n",
    "        r, c = 4, 4\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        generatedImage = 0.5 * self.generator.predict(noise) + 0.5\n",
    "        \n",
    "        fig = plt.figure(figsize=(10,10))\n",
    "        \n",
    "        axs = [fig.add_subplot(r,c,i+1) for i in range(r*c)]\n",
    "        cnt = 0\n",
    "        for ax in axs:\n",
    "            ax.imshow(generatedImage[cnt],interpolation='nearest')\n",
    "            ax.axis('off')\n",
    "            ax.set_aspect('equal')\n",
    "            cnt+=1\n",
    "        fig.subplots_adjust(wspace=.008, hspace=.03)\n",
    "    \n",
    "        path = 'results/'+folder+'/samples'\n",
    "        if not os.path.exists('results'):\n",
    "            os.mkdir('results')\n",
    "        if not os.path.exists('results/'+folder):\n",
    "            os.mkdir('results/'+folder)\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        fig.savefig(path+'/epoch_%d.png' % epoch)\n",
    "        plt.close()\n",
    "\n",
    "    def save_models(self, name, epoch):\n",
    "        path = 'results/'+name+'/models'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        self.generator.save(path+'/G_%d.h5' % epoch)\n",
    "        self.critic.save(path+'/D_%d.h5' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327680, 64, 64, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train = (h5py.File('camelyonpatch_level_2_split_train_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "# x_test = (h5py.File('camelyonpatch_level_2_split_test_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "# x_valid = (h5py.File('camelyonpatch_level_2_split_valid_x.h5', 'r')['x'][:, 16:80,16:80] - 127.5) / 127.5\n",
    "# X = np.concatenate([x_train, x_test, x_valid])\n",
    "\n",
    "X = h5py.File('X.hdf5', 'r')['X'][:]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGANGP(64, 64, 3)\n",
    "wgan.train(X, epochs=10000, batch_size=512, sample_interval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = h5py.File('camelyonpatch_level_2_split_train_y.h5', 'r')['y'][:].reshape(-1,1)\n",
    "y_test = h5py.File('camelyonpatch_level_2_split_test_y.h5', 'r')['y'][:].reshape(-1,1)\n",
    "y_valid = h5py.File('camelyonpatch_level_2_split_valid_y.h5', 'r')['y'][:].reshape(-1,1)\n",
    "          \n",
    "Y = np.concatenate([y_train, y_test, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}